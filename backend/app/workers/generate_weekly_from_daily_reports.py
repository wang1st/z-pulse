#!/usr/bin/env python3
"""
åŸºäºæ™¨æŠ¥ç”Ÿæˆå‘¨æŠ¥ï¼ˆæ­£ç¡®çš„é€»è¾‘ï¼‰
"""
import sys
from pathlib import Path
from datetime import date, timedelta, datetime, timezone
from typing import Optional
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, '/app')

from shared.database import SessionLocal, Report, ReportType
from backend.app.workers.ai_generate import AIWorker
from shared.utils import get_logger
from bs4 import BeautifulSoup

logger = get_logger("generate_weekly_from_daily")

def extract_text_from_html(html_content):
    """ä»HTMLä¸­æå–çº¯æ–‡æœ¬å†…å®¹"""
    try:
        soup = BeautifulSoup(html_content, 'html.parser')
        # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
        for script in soup(["script", "style"]):
            script.decompose()
        text = soup.get_text(separator='\n', strip=True)
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        return '\n'.join(lines)
    except:
        return html_content

def generate_weekly_from_daily_reports(target_date: Optional[date] = None, send_emails: bool = True):
    """
    åŸºäºè¿‡å»7å¤©çš„æ™¨æŠ¥ç”Ÿæˆå‘¨æŠ¥

    Args:
        target_date: ç›®æ ‡æ—¥æœŸï¼ˆå‘¨ä¸€ï¼‰
        send_emails: æ˜¯å¦å‘é€é‚®ä»¶
    """
    db = SessionLocal()

    try:
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹ç”Ÿæˆå‘¨æŠ¥ï¼ˆåŸºäºæ™¨æŠ¥ï¼‰")
        logger.info("=" * 80)

        # ç¡®å®šæ—¥æœŸèŒƒå›´
        end_date = target_date if target_date else datetime.now().date()
        start_date = end_date - timedelta(days=6)

        logger.info(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")

        # æŸ¥è¯¢è¿‡å»7å¤©çš„æ™¨æŠ¥
        daily_reports = db.query(Report).filter(
            Report.report_type == ReportType.DAILY,
            Report.report_date >= start_date,
            Report.report_date <= end_date
        ).order_by(Report.report_date).all()

        logger.info(f"âœ… æ‰¾åˆ° {len(daily_reports)} ç¯‡æ™¨æŠ¥")

        if len(daily_reports) == 0:
            logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ™¨æŠ¥")
            return None

        # å‡†å¤‡æ¯æ—¥æ‘˜è¦
        logger.info("ğŸ“ å‡†å¤‡æ¯æ—¥æ‘˜è¦...")
        daily_summaries = {}

        for report in daily_reports:
            date_str = report.report_date.strftime('%Yå¹´%mæœˆ%dæ—¥')

            # ä»HTMLä¸­æå–çº¯æ–‡æœ¬
            content = extract_text_from_html(report.summary_markdown or '')

            # å–å‰500å­—ä½œä¸ºæ‘˜è¦
            preview = content[:500] if len(content) > 500 else content

            daily_summaries[date_str] = preview
            logger.info(f"  ğŸ“… {date_str}: {len(content)} å­—ç¬¦, é¢„è§ˆ: {len(preview)} å­—ç¬¦")

        logger.info(f"âœ… æ€»å…±å‡†å¤‡äº† {len(daily_summaries)} å¤©çš„æ™¨æŠ¥æ‘˜è¦")

        # ç”Ÿæˆå‘¨æŠ¥
        date_range = f"{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {end_date.strftime('%mæœˆ%dæ—¥')}"
        logger.info(f"ğŸ“Š æ—¥æœŸèŒƒå›´: {date_range}")
        logger.info(f"ğŸ“Š å‡†å¤‡ç”Ÿæˆå‘¨æŠ¥ç»¼è¿°ï¼Œè¾“å…¥æ•°æ®å¤§å°: {sum(len(v) for v in daily_summaries.values())} å­—ç¬¦")

        logger.info("ğŸ¤– è°ƒç”¨Qwenç”Ÿæˆå‘¨æŠ¥ç»¼è¿°...")
        worker = AIWorker()

        markdown_content = worker._generate_weekly_analysis_with_qwen(
            topics=[],
            daily_summaries=daily_summaries,
            date_range=date_range
        )

        if not markdown_content:
            logger.error("âŒ å‘¨æŠ¥ç”Ÿæˆå¤±è´¥ï¼šQwen APIè¿”å›ç©ºå†…å®¹")
            return None

        logger.info(f"âœ… Qwenè¿”å›å†…å®¹é•¿åº¦: {len(markdown_content)} å­—ç¬¦")

        # æ·»åŠ å…è´£å£°æ˜
        disclaimer = "\n\n---\n\n**å…è´£å£°æ˜**ï¼šæœ¬æŠ¥å‘Šç”±å¤§æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆï¼Œå†…å®¹åŸºäºå…¬å¼€ä¿¡æ¯è¿›è¡Œæ€»ç»“å’Œåˆ†æï¼Œä»…ä½œä¸ºä¸åŒè§†è§’çš„å‚è€ƒï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®æˆ–å†³ç­–ä¾æ®ã€‚"
        markdown_content_with_disclaimer = markdown_content + disclaimer

        # ä¿å­˜åˆ°æ•°æ®åº“
        logger.info("ğŸ’¾ ä¿å­˜å‘¨æŠ¥åˆ°æ•°æ®åº“...")

        existing_weekly = db.query(Report).filter(
            Report.report_type == ReportType.WEEKLY,
            Report.report_date == end_date
        ).first()

        if existing_weekly:
            logger.info(f"ğŸ”„ æ›´æ–°ç°æœ‰å‘¨æŠ¥ï¼ˆID: {existing_weekly.id}ï¼‰")
            existing_weekly.summary_markdown = markdown_content_with_disclaimer
            existing_weekly.title = f"è´¢æ”¿å‘¨æŠ¥è¿°è¯„ - {date_range}"
            existing_weekly.article_count = len(daily_reports)
            weekly_report = existing_weekly
        else:
            logger.info("â• åˆ›å»ºæ–°å‘¨æŠ¥")
            weekly_report = Report(
                report_type=ReportType.WEEKLY,
                report_date=end_date,
                title=f"è´¢æ”¿å‘¨æŠ¥è¿°è¯„ - {date_range}",
                summary_markdown=markdown_content_with_disclaimer,
                article_count=len(daily_reports),
                sent_count=0,
                view_count=0
            )
            db.add(weekly_report)

        db.commit()
        db.flush()
        db.refresh(weekly_report)

        logger.info("=" * 80)
        logger.info(f"âœ… å‘¨æŠ¥ç”ŸæˆæˆåŠŸï¼")
        logger.info(f"   ğŸ†” å‘¨æŠ¥ID: {weekly_report.id}")
        logger.info(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {date_range}")
        logger.info(f"   ğŸ“° æ ‡é¢˜: {weekly_report.title}")
        logger.info(f"   ğŸ“Š åŸºäºæ™¨æŠ¥æ•°é‡: {len(daily_reports)}")
        logger.info(f"   ğŸ“ å†…å®¹é•¿åº¦: {len(weekly_report.summary_markdown or '')} å­—ç¬¦")
        logger.info("=" * 80)

        # å‘é€é‚®ä»¶
        if send_emails:
            logger.info("\nğŸ“§ å¼€å§‹å‘é€å‘¨æŠ¥é‚®ä»¶...")

            from shared.database import Subscriber
            subscribers = db.query(Subscriber).filter(
                Subscriber.is_active.is_(True),
                Subscriber.subscribe_weekly.is_(True)
            ).all()

            logger.info(f"ğŸ‘¥ æ‰¾åˆ° {len(subscribers)} ä¸ªè®¢é˜…å‘¨æŠ¥çš„ç”¨æˆ·")

            if len(subscribers) > 0:
                try:
                    sent_count = worker._distribute_weekly_report(db, weekly_report)
                    logger.info(f"âœ… æˆåŠŸå‘é€ {sent_count} å°é‚®ä»¶")

                    weekly_report.sent_count = sent_count
                    db.commit()
                    db.refresh(weekly_report)

                    logger.info(f"   ğŸ“¬ å‘é€æ•°é‡: {weekly_report.sent_count}")

                except Exception as e:
                    logger.error(f"âŒ å‘é€é‚®ä»¶å¤±è´¥: {str(e)}", exc_info=True)
            else:
                logger.info("â„¹ï¸  æ²¡æœ‰è®¢é˜…å‘¨æŠ¥çš„ç”¨æˆ·ï¼Œè·³è¿‡å‘é€")

        return weekly_report

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå‘¨æŠ¥å¤±è´¥: {str(e)}", exc_info=True)
        db.rollback()
        raise
    finally:
        db.close()

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='åŸºäºæ™¨æŠ¥ç”Ÿæˆå‘¨æŠ¥')
    parser.add_argument('--date', type=str, help='ç›®æ ‡æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸ºä»Šå¤©')
    parser.add_argument('--no-send', action='store_true', help='ä¸å‘é€é‚®ä»¶')

    args = parser.parse_args()

    # è§£ææ—¥æœŸ
    target_date = None
    if args.date:
        try:
            target_date = datetime.strptime(args.date, '%Y-%m-%d').date()
        except ValueError:
            logger.error(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {args.date}ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            return

    logger.info(f"âš™ï¸  é…ç½®: target_date={target_date or 'ä»Šå¤©'}, send_emails={not args.no_send}")

    # ç”Ÿæˆå‘¨æŠ¥
    report = generate_weekly_from_daily_reports(
        target_date=target_date,
        send_emails=not args.no_send
    )

    if report:
        logger.info(f"\nâœ… å‘¨æŠ¥ç”Ÿæˆå®Œæˆï¼ID: {report.id}")
    else:
        logger.error("\nâŒ å‘¨æŠ¥ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()
