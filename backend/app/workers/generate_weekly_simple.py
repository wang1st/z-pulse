#!/usr/bin/env python
"""
ç®€åŒ–ç‰ˆå‘¨æŠ¥ç”Ÿæˆè„šæœ¬ï¼ˆå¸¦è¯¦ç»†è°ƒè¯•ä¿¡æ¯ï¼‰
"""
import sys
from pathlib import Path
from datetime import date, timedelta, datetime, timezone
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, '/app')

from shared.database import SessionLocal, Report, ReportType, Article, Subscriber
from backend.app.workers.ai_generate import AIWorker
from shared.utils import get_logger

logger = get_logger("generate_weekly_simple")

def generate_weekly_report_simple(target_date: Optional[date] = None, send_emails: bool = True, max_articles: int = 100):
    """
    ç®€åŒ–ç‰ˆå‘¨æŠ¥ç”Ÿæˆ

    æµç¨‹ï¼š
    1. è·å–è¿‡å»7å¤©çš„æ‰€æœ‰æ–‡ç« 
    2. éšæœºæŠ½å–æœ€å¤šmax_articlesç¯‡æ–‡ç« 
    3. æŒ‰æ—¥æœŸåˆ†ç»„
    4. ä½¿ç”¨Qwenç”Ÿæˆå‘¨æŠ¥
    5. å­˜å…¥æ•°æ®åº“

    Args:
        target_date: ç›®æ ‡æ—¥æœŸï¼ˆå‘¨ä¸€ï¼‰
        send_emails: æ˜¯å¦å‘é€é‚®ä»¶
        max_articles: æœ€å¤§å¤„ç†æ–‡ç« æ•°
    """
    db = SessionLocal()

    try:
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹ç”Ÿæˆå‘¨æŠ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰")
        logger.info("=" * 80)

        # ç¡®å®šæ—¥æœŸèŒƒå›´
        end_date = target_date if target_date else datetime.now().date()
        start_date = end_date - timedelta(days=6)

        logger.info(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")

        # æŸ¥è¯¢æ–‡ç« 
        start_utc = datetime.combine(start_date, datetime.min.time(), tzinfo=timezone.utc)
        end_utc = datetime.combine(end_date, datetime.max.time(), tzinfo=timezone.utc)

        logger.info(f"ğŸ” æŸ¥è¯¢æ–‡ç« æ—¶é—´èŒƒå›´: {start_utc} è‡³ {end_utc}")

        articles = db.query(Article).filter(
            Article.published_at >= start_utc,
            Article.published_at <= end_utc
        ).order_by(Article.published_at).all()

        logger.info(f"âœ… æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")

        if len(articles) == 0:
            logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ç« ")
            return None

        # é™åˆ¶æ–‡ç« æ•°é‡
        if len(articles) > max_articles:
            logger.info(f"ğŸ“Š æ–‡ç« æ•°é‡è¶…è¿‡é™åˆ¶ï¼Œä» {len(articles)} ç¯‡ä¸­éšæœºæŠ½å– {max_articles} ç¯‡")
            import random
            articles = random.sample(articles, max_articles)

        logger.info(f"ğŸ“ å‡†å¤‡å¤„ç† {len(articles)} ç¯‡æ–‡ç« ")

        # ä½¿ç”¨AI Workerç­›é€‰è´¢æ”¿ç›¸å…³æ–‡ç« 
        logger.info("ğŸ”§ å¼€å§‹ç­›é€‰è´¢æ”¿ç›¸å…³æ–‡ç« ...")
        worker = AIWorker()

        try:
            finance_articles = worker._filter_finance_related_articles(articles)
            logger.info(f"âœ… ç­›é€‰å‡º {len(finance_articles)} ç¯‡è´¢æ”¿ç›¸å…³æ–‡ç« ")
        except Exception as e:
            logger.error(f"âŒ ç­›é€‰æ–‡ç« å¤±è´¥: {str(e)}", exc_info=True)
            logger.info("âš ï¸  ä½¿ç”¨æ‰€æœ‰æ–‡ç« ç»§ç»­å¤„ç†")
            finance_articles = articles

        if not finance_articles:
            logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è´¢æ”¿ç›¸å…³æ–‡ç« ")
            return None

        # æŒ‰æ—¥æœŸåˆ†ç»„
        logger.info("ğŸ“… æŒ‰æ—¥æœŸåˆ†ç»„æ–‡ç« ...")
        from collections import defaultdict
        articles_by_date = defaultdict(list)

        for article in finance_articles:
            pub_date = article.published_at
            if pub_date.tzinfo is None:
                pub_date = pub_date.replace(tzinfo=timezone.utc)
            local_date = pub_date.astimezone(timezone.utc).date()
            articles_by_date[local_date].append(article)
            logger.debug(f"  æ–‡ç« : {local_date} - {article.title[:50]}...")

        logger.info(f"âœ… æ–‡ç« å·²åˆ†ç»„åˆ° {len(articles_by_date)} ä¸ªæ—¥æœŸ")

        # å‡†å¤‡æ¯æ—¥æ‘˜è¦
        logger.info("ğŸ“ å‡†å¤‡æ¯æ—¥æ‘˜è¦...")
        daily_summaries = {}

        for day, day_articles in sorted(articles_by_date.items()):
            date_str = day.strftime('%Yå¹´%mæœˆ%dæ—¥')
            logger.info(f"  ğŸ“… {date_str}: {len(day_articles)} ç¯‡æ–‡ç« ")

            article_summaries = []
            for i, article in enumerate(day_articles[:15], 1):  # æ¯å¤©æœ€å¤š15ç¯‡
                title = getattr(article, 'title', '') or ''
                content = getattr(article, 'content', '') or ''

                # å–å‰200å­—ä½œä¸ºæ‘˜è¦
                preview = content[:200] if content else ''
                article_text = f"{title}ã€‚{preview}".strip()

                if article_text:
                    article_summaries.append(article_text)
                    logger.debug(f"    [{i}] {title[:50]}...")

            # åˆå¹¶æ‘˜è¦
            if article_summaries:
                daily_summary = " | ".join(article_summaries[:8])  # æ¯å¤©æœ€å¤š8ç¯‡
                daily_summaries[date_str] = daily_summary
                logger.info(f"    âœ… å‡†å¤‡äº† {len(article_summaries)} ç¯‡æ‘˜è¦")

        logger.info(f"âœ… æ€»å…±å‡†å¤‡äº† {len(daily_summaries)} å¤©çš„æ‘˜è¦")

        if not daily_summaries:
            logger.warning("âš ï¸  æ²¡æœ‰æå–åˆ°ä»»ä½•æ‘˜è¦")
            return None

        # ç”Ÿæˆå‘¨æŠ¥
        date_range = f"{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {end_date.strftime('%mæœˆ%dæ—¥')}"
        logger.info(f"ğŸ“Š æ—¥æœŸèŒƒå›´å­—ç¬¦ä¸²: {date_range}")
        logger.info(f"ğŸ“Š å‡†å¤‡ç”Ÿæˆå‘¨æŠ¥ç»¼è¿°ï¼Œè¾“å…¥æ•°æ®å¤§å°: {sum(len(v) for v in daily_summaries.values())} å­—ç¬¦")

        logger.info("ğŸ¤– è°ƒç”¨Qwenç”Ÿæˆå‘¨æŠ¥ç»¼è¿°...")
        markdown_content = worker._generate_weekly_analysis_with_qwen(
            topics=[],
            daily_summaries=daily_summaries,
            date_range=date_range
        )

        if not markdown_content:
            logger.error("âŒ å‘¨æŠ¥ç”Ÿæˆå¤±è´¥ï¼šQwen APIè¿”å›ç©ºå†…å®¹")
            return None

        logger.info(f"âœ… Qwenè¿”å›å†…å®¹é•¿åº¦: {len(markdown_content)} å­—ç¬¦")
        logger.info(f"ğŸ“„ å†…å®¹é¢„è§ˆ: {markdown_content[:200]}...")

        # æ·»åŠ å…è´£å£°æ˜
        disclaimer = "\n\n---\n\n**å…è´£å£°æ˜**ï¼šæœ¬æŠ¥å‘Šç”±å¤§æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆï¼Œå†…å®¹åŸºäºå…¬å¼€ä¿¡æ¯è¿›è¡Œæ€»ç»“å’Œåˆ†æï¼Œä»…ä½œä¸ºä¸åŒè§†è§’çš„å‚è€ƒï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®æˆ–å†³ç­–ä¾æ®ã€‚"
        markdown_content_with_disclaimer = markdown_content + disclaimer

        # ä¿å­˜åˆ°æ•°æ®åº“
        logger.info("ğŸ’¾ ä¿å­˜å‘¨æŠ¥åˆ°æ•°æ®åº“...")

        existing_weekly = db.query(Report).filter(
            Report.report_type == ReportType.WEEKLY,
            Report.report_date == end_date
        ).first()

        if existing_weekly:
            logger.info(f"ğŸ”„ æ›´æ–°ç°æœ‰å‘¨æŠ¥ï¼ˆID: {existing_weekly.id}ï¼‰")
            existing_weekly.summary_markdown = markdown_content_with_disclaimer
            existing_weekly.title = f"è´¢æ”¿å‘¨æŠ¥è¿°è¯„ - {date_range}"
            existing_weekly.article_count = len(finance_articles)
            weekly_report = existing_weekly
        else:
            logger.info("â• åˆ›å»ºæ–°å‘¨æŠ¥")
            weekly_report = Report(
                report_type=ReportType.WEEKLY,
                report_date=end_date,
                title=f"è´¢æ”¿å‘¨æŠ¥è¿°è¯„ - {date_range}",
                summary_markdown=markdown_content_with_disclaimer,
                article_count=len(finance_articles),
                sent_count=0,
                view_count=0
            )
            db.add(weekly_report)

        db.commit()
        db.flush()
        db.refresh(weekly_report)

        logger.info("=" * 80)
        logger.info(f"âœ… å‘¨æŠ¥ç”ŸæˆæˆåŠŸï¼")
        logger.info(f"   ğŸ†” å‘¨æŠ¥ID: {weekly_report.id}")
        logger.info(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {date_range}")
        logger.info(f"   ğŸ“° æ ‡é¢˜: {weekly_report.title}")
        logger.info(f"   ğŸ“Š æ–‡ç« æ•°é‡: {len(finance_articles)}")
        logger.info(f"   ğŸ“ å†…å®¹é•¿åº¦: {len(weekly_report.summary_markdown or '')} å­—ç¬¦")
        logger.info("=" * 80)

        # å‘é€é‚®ä»¶
        if send_emails:
            logger.info("\nğŸ“§ å¼€å§‹å‘é€å‘¨æŠ¥é‚®ä»¶...")

            subscribers = db.query(Subscriber).filter(
                Subscriber.is_active.is_(True),
                Subscriber.subscribe_weekly.is_(True)
            ).all()

            logger.info(f"ğŸ‘¥ æ‰¾åˆ° {len(subscribers)} ä¸ªè®¢é˜…å‘¨æŠ¥çš„ç”¨æˆ·")

            if len(subscribers) > 0:
                try:
                    logger.info("ğŸ“® è°ƒç”¨é‚®ä»¶å‘é€æœåŠ¡...")
                    sent_count = worker._distribute_weekly_report(db, weekly_report)
                    logger.info(f"âœ… æˆåŠŸå‘é€ {sent_count} å°é‚®ä»¶")

                    weekly_report.sent_count = sent_count
                    db.commit()
                    db.refresh(weekly_report)

                    logger.info(f"   ğŸ“¬ å‘é€æ•°é‡: {weekly_report.sent_count}")

                except Exception as e:
                    logger.error(f"âŒ å‘é€é‚®ä»¶å¤±è´¥: {str(e)}", exc_info=True)
            else:
                logger.info("â„¹ï¸  æ²¡æœ‰è®¢é˜…å‘¨æŠ¥çš„ç”¨æˆ·ï¼Œè·³è¿‡å‘é€")

        return weekly_report

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå‘¨æŠ¥å¤±è´¥: {str(e)}", exc_info=True)
        db.rollback()
        raise
    finally:
        db.close()

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='ç”Ÿæˆå‘¨æŠ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰')
    parser.add_argument('--date', type=str, help='ç›®æ ‡æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸ºä»Šå¤©')
    parser.add_argument('--no-send', action='store_true', help='ä¸å‘é€é‚®ä»¶')
    parser.add_argument('--max-articles', type=int, default=100, help='æœ€å¤§å¤„ç†æ–‡ç« æ•°ï¼ˆé»˜è®¤100ï¼‰')

    args = parser.parse_args()

    # è§£ææ—¥æœŸ
    target_date = None
    if args.date:
        try:
            target_date = datetime.strptime(args.date, '%Y-%m-%d').date()
        except ValueError:
            logger.error(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {args.date}ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            return

    logger.info(f"âš™ï¸  é…ç½®: target_date={target_date or 'ä»Šå¤©'}, send_emails={not args.no_send}, max_articles={args.max_articles}")

    # ç”Ÿæˆå‘¨æŠ¥
    report = generate_weekly_report_simple(
        target_date=target_date,
        send_emails=not args.no_send,
        max_articles=args.max_articles
    )

    if report:
        logger.info(f"\nâœ… å‘¨æŠ¥ç”Ÿæˆå®Œæˆï¼ID: {report.id}")
    else:
        logger.error("\nâŒ å‘¨æŠ¥ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()
